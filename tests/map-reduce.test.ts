import { Node, run, Action } from '../src';
import { mockLLM } from './mock-llm';

/**
 * # Tutorial: Summarizing Multiple Documents with Parallel Processing
 *
 * > **[View example code](../../tests/map-reduce.test.ts)**
 *
 * ## What Will Be Built
 *
 * A document summarization pipeline that processes multiple documents in parallel and
 * combines their summaries into a single cohesive overview. Three documents will be
 * summarized concurrently, then their individual summaries will be merged into one
 * final summary.
 *
 * Input:  { documents: ['Doc 1...', 'Doc 2...', 'Doc 3...'] }
 * Output: { summaries: ['Summary 1', 'Summary 2', 'Summary 3'], finalSummary: '...' }
 *
 * ## Workflow Diagram
 *
 * ```mermaid
 * graph LR
 *     Store1["Store (before)
 *     ―――――――――――――
 *     documents: [
 *       'Doc 1...',
 *       'Doc 2...',
 *       'Doc 3...'
 *     ]"]
 *
 *     subgraph MapPhase["MapNode (parallel execution)"]
 *         direction TB
 *         Prep["prep() yields 3 docs"]
 *         Exec1["exec('Doc 1...')"]
 *         Exec2["exec('Doc 2...')"]
 *         Exec3["exec('Doc 3...')"]
 *         Post["post() collects summaries"]
 *
 *         Prep --> Exec1
 *         Prep --> Exec2
 *         Prep --> Exec3
 *         Exec1 --> Post
 *         Exec2 --> Post
 *         Exec3 --> Post
 *     end
 *
 *     Store2["Store (intermediate)
 *     ―――――――――――――
 *     summaries: [
 *       'Summary 1',
 *       'Summary 2',
 *       'Summary 3'
 *     ]"]
 *
 *     subgraph ReducePhase["ReduceNode"]
 *         Reduce["prep() combines summaries
 *         ↓
 *         exec() generates final summary
 *         ↓
 *         post() stores result"]
 *     end
 *
 *     Store3["Store (final)
 *     ―――――――――――――
 *     finalSummary:
 *       'Combined...'"]
 *
 *     Store1 --> MapPhase
 *     MapPhase --> Store2
 *     Store2 --> ReducePhase
 *     ReducePhase --> Store3
 * ```
 *
 * ## Implementation
 *
 * The workflow is divided into two phases:
 *
 * **Map Phase (MapNode)**: Each document from the store will be yielded individually
 * by `prep()`. All documents will be processed concurrently by separate `exec()` calls.
 * The individual summaries will be collected and stored in the shared state by `post()`,
 * which then transitions to the ReduceNode via the default edge.
 *
 * **Reduce Phase (ReduceNode)**: All individual summaries will be combined into a single
 * prompt by `prep()`. The combined summary will be generated by `exec()`. The final result
 * will be stored by `post()`.
 *
 * @example
 * const store: MapReduceStore = {
 *   documents: [
 *     'Document 1: Introduction to AI...',
 *     'Document 2: Machine Learning basics...',
 *     'Document 3: Deep Learning advances...'
 *   ]
 * };
 *
 * const mapNode = new MapNode();
 * const reduceNode = new ReduceNode();
 *
 * // Connect map phase to reduce phase
 * mapNode.connect(reduceNode);
 *
 * // Run the pipeline - documents will be processed in parallel
 * await run(mapNode, store);
 *
 * // Access the results
 * console.log(store.summaries);    // ['Summary 1', 'Summary 2', 'Summary 3']
 * console.log(store.finalSummary); // 'Combined summary of all documents'
 */

interface MapReduceStore {
  documents: string[];
  summaries?: string[];
  finalSummary?: string;
}

class MapNode extends Node<MapReduceStore, string, string> {
  async *prep(store: MapReduceStore) {
    for (const doc of store.documents) {
      yield doc;
    }
  }

  async exec(store: MapReduceStore, doc: string): Promise<string> {
    return mockLLM.call(`Summarize: ${doc}`);
  }

  async post(
    store: MapReduceStore,
    prepItems: string[],
    execResults: string[]
  ): Promise<Action> {
    store.summaries = execResults;
    return 'default';
  }
}

class ReduceNode extends Node<MapReduceStore, string, string> {
  async *prep(store: MapReduceStore) {
    const allSummaries = store.summaries!.join('\n---\n');
    yield `Combine these summaries into one: ${allSummaries}`;
  }

  async exec(store: MapReduceStore, prompt: string): Promise<string> {
    return mockLLM.call(prompt);
  }

  async post(
    store: MapReduceStore,
    prepItems: string[],
    execResults: string[]
  ): Promise<Action> {
    store.finalSummary = execResults[0];
    return null;
  }
}

describe('Map-Reduce Pattern', () => {
  test('processes multiple items in parallel then aggregates', async () => {
    const store: MapReduceStore = {
      documents: [
        'Document 1: Introduction to AI...',
        'Document 2: Machine Learning basics...',
        'Document 3: Deep Learning advances...'
      ]
    };

    const mapNode = new MapNode();
    const reduceNode = new ReduceNode();

    mapNode.connect(reduceNode);

    await run(mapNode, store);

    expect(store.summaries).toHaveLength(3);
    expect(store.finalSummary).toBeDefined();
  });
});
